
import os
import glob
from pathlib import Path
import streamlit as st
import re

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ë¡œë“œ
try:
    # from langchain_openai import ChatOpenAI, OpenAIEmbeddings
    # from langchain.prompts import ChatPromptTemplate
    # from langchain.schema.output_parser import StrOutputParser
    # from langchain_community.document_loaders import TextLoader
    # from langchain_text_splitters import RecursiveCharacterTextSplitter
    # from langchain_community.vectorstores import Chroma
    # LangChain (ìˆ˜ì •ëœ ë²„ì „)
    from langchain_openai import ChatOpenAI, OpenAIEmbeddings
    from langchain_core.prompts import ChatPromptTemplate              
    from langchain_core.output_parsers import StrOutputParser          
    from langchain_community.document_loaders import TextLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import Chroma
except ImportError as e:
    st.error(f"í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: {e}")
    st.stop()

# ==========================================
# í˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(page_title="í•­ê³µê¶Œ í™˜ë¶ˆ ìƒë‹´ RAG ì±—ë´‡", layout="wide")
st.title("âœˆï¸ ì—¬í–‰ ì·¨ì†ŒÂ·í™˜ë¶ˆ ìƒë‹´ ì±—ë´‡")
st.markdown("### ğŸ§³ ì•„ ëª°ë‘~ í™˜ë¶ˆí•´ì¤˜~")

# ==========================================
# ìƒìˆ˜ ì •ì˜
# ==========================================

# í•œì˜ ë™ì˜ì–´ ë§¤í•‘ (ê²€ìƒ‰ ê°œì„ ìš©)
SYNONYM_DICT = {
    # ë…¸ì‡¼ ê´€ë ¨
    "ë…¸ì‡¼": ["ë…¸ì‡¼", "No-Show", "no-show", "ë…¸ ì‡¼", "ë¯¸íƒ‘ìŠ¹", "ì˜ˆì•½ë¶€ë„"],
    "no-show": ["ë…¸ì‡¼", "No-Show", "no-show", "ë¯¸íƒ‘ìŠ¹", "ì˜ˆì•½ë¶€ë„"],

    # í™˜ë¶ˆ ê´€ë ¨
    "í™˜ë¶ˆ": ["í™˜ë¶ˆ", "refund", "ë°˜í™˜", "ì·¨ì†Œí™˜ë¶ˆ"],
    "refund": ["í™˜ë¶ˆ", "refund", "ë°˜í™˜"],

    # ë³€ê²½ ê´€ë ¨
    "ë³€ê²½": ["ë³€ê²½", "change", "ìˆ˜ì •", "êµí™˜"],
    "change": ["ë³€ê²½", "change", "ìˆ˜ì •"],

    # ìˆ˜ìˆ˜ë£Œ ê´€ë ¨
    "ìˆ˜ìˆ˜ë£Œ": ["ìˆ˜ìˆ˜ë£Œ", "fee", "ìš”ê¸ˆ", "ë¹„ìš©", "charge", "ìœ„ì•½ê¸ˆ", "íŒ¨ë„í‹°", "penalty"],
    "fee": ["ìˆ˜ìˆ˜ë£Œ", "fee", "ìš”ê¸ˆ", "ë¹„ìš©", "charge", "ìœ„ì•½ê¸ˆ", "íŒ¨ë„í‹°", "penalty"],
    "ìœ„ì•½ê¸ˆ": ["ìœ„ì•½ê¸ˆ", "íŒ¨ë„í‹°", "penalty", "ìˆ˜ìˆ˜ë£Œ", "fee"],

    # ì·¨ì†Œ ê´€ë ¨
    "ì·¨ì†Œ": ["ì·¨ì†Œ", "cancel", "cancellation", "í•´ì§€"],
    "cancel": ["ì·¨ì†Œ", "cancel", "cancellation"],

    # ìš´ì„ ì¢…ë¥˜ (ì´ìŠ¤íƒ€í•­ê³µ, ì•„ì‹œì•„ë‚˜ ë“±)
    "íŠ¹ê°€": ["íŠ¹ê°€", "íŠ¹ê°€ìš´ì„", "í”„ë¡œëª¨ì…˜", "promotion", "special"],
    "íŠ¹ê°€ìš´ì„": ["íŠ¹ê°€", "íŠ¹ê°€ìš´ì„", "í”„ë¡œëª¨ì…˜", "special fare"],
    "í• ì¸": ["í• ì¸", "í• ì¸ìš´ì„", "discount", "ì„¸ì¼", "sale"],
    "í• ì¸ìš´ì„": ["í• ì¸", "í• ì¸ìš´ì„", "discount fare"],
    "ì¼ë°˜": ["ì¼ë°˜", "ì¼ë°˜ìš´ì„", "ì •ìƒ", "ì •ìƒìš´ì„", "normal", "regular"],
    "ì¼ë°˜ìš´ì„": ["ì¼ë°˜", "ì¼ë°˜ìš´ì„", "ì •ìƒìš´ì„", "regular fare"],

    # ìš´ì„ ë“±ê¸‰ (ì œì£¼í•­ê³µ, ëŒ€í•œí•­ê³µ ë“±)
    "ë² ì´ì§": ["ë² ì´ì§", "BASIC", "Basic", "basic"],
    "basic": ["ë² ì´ì§", "BASIC", "Basic"],
    "ìŠ¤íƒ ë‹¤ë“œ": ["ìŠ¤íƒ ë‹¤ë“œ", "STANDARD", "Standard", "standard"],
    "standard": ["ìŠ¤íƒ ë‹¤ë“œ", "STANDARD", "Standard"],
    "í”Œë ‰ìŠ¤": ["í”Œë ‰ìŠ¤", "FLEX", "Flex", "flex", "flexible"],
    "flex": ["í”Œë ‰ìŠ¤", "FLEX", "Flex", "flexible"],
    "ì„¸ì´ë²„": ["ì„¸ì´ë²„", "SAVER", "Saver", "saver"],
    "saver": ["ì„¸ì´ë²„", "SAVER", "Saver"],

    # ë…¸ì„  ê´€ë ¨
    "êµ­ë‚´ì„ ": ["êµ­ë‚´ì„ ", "domestic", "êµ­ë‚´"],
    "domestic": ["êµ­ë‚´ì„ ", "domestic"],
    "êµ­ì œì„ ": ["êµ­ì œì„ ", "international", "êµ­ì œ", "í•´ì™¸", "ì™¸êµ­"],
    "international": ["êµ­ì œì„ ", "international"],

    # íƒ‘ìŠ¹ìˆ˜ì† ê´€ë ¨
    "íƒ‘ìŠ¹ìˆ˜ì†": ["íƒ‘ìŠ¹ìˆ˜ì†", "ì²´í¬ì¸", "check-in", "ìˆ˜ì†"],
    "ì²´í¬ì¸": ["íƒ‘ìŠ¹ìˆ˜ì†", "ì²´í¬ì¸", "check-in"],

    # Gate No-Show ê´€ë ¨
    "ê²Œì´íŠ¸": ["ê²Œì´íŠ¸", "gate", "ì¶œêµ¬ì¥"],
    "ì¶œêµ¬ì¥": ["ê²Œì´íŠ¸", "gate", "ì¶œêµ¬ì¥"],

    # ë¯¸íƒ‘ìŠ¹ ì„¸ë¶„í™”
    "ë¯¸íƒ‘ìŠ¹": ["ë¯¸íƒ‘ìŠ¹", "no-show", "ë¯¸ìŠ¹ì„ ", "ë¶ˆíƒ‘ìŠ¹"]
}


# í•­ê³µì‚¬ ë§¤í•‘ (íŒŒì¼ëª… â†’ í‘œì¤€ëª…)
AIRLINE_MAPPING = {
    "ëŒ€í•œí•­ê³µ": "ëŒ€í•œí•­ê³µ",
    "koreanair": "ëŒ€í•œí•­ê³µ",
    "korean": "ëŒ€í•œí•­ê³µ",
    "ì œì£¼í•­ê³µ": "ì œì£¼í•­ê³µ",
    "jejuair": "ì œì£¼í•­ê³µ",
    "jeju": "ì œì£¼í•­ê³µ",
    "ì•„ì‹œì•„ë‚˜": "ì•„ì‹œì•„ë‚˜",
    "asiana": "ì•„ì‹œì•„ë‚˜",
    "ì§„ì—ì–´": "ì§„ì—ì–´",
    "jinair": "ì§„ì—ì–´",
    "jin": "ì§„ì—ì–´",
    "í‹°ì›¨ì´": "í‹°ì›¨ì´",
    "twayair": "í‹°ì›¨ì´",
    "tway": "í‹°ì›¨ì´",
    "ì—ì–´ì„œìš¸": "ì—ì–´ì„œìš¸",
    "airseoul": "ì—ì–´ì„œìš¸",
    "ì´ìŠ¤íƒ€í•­ê³µ": "ì´ìŠ¤íƒ€í•­ê³µ",
    "ì´ìŠ¤íƒ€": "ì´ìŠ¤íƒ€í•­ê³µ",
    "eastar": "ì´ìŠ¤íƒ€í•­ê³µ",
}

# í•­ê³µì‚¬ í‚¤ì›Œë“œ (ì§ˆë¬¸ì—ì„œ ì¶”ì¶œìš©)
AIRLINE_KEYWORDS = {
    "ëŒ€í•œí•­ê³µ": ["ëŒ€í•œí•­ê³µ", "ëŒ€í•œ", "koreanair", "korean air", "kal"],
    "ì œì£¼í•­ê³µ": ["ì œì£¼í•­ê³µ", "ì œì£¼", "jejuair", "jeju air"],
    "ì•„ì‹œì•„ë‚˜": ["ì•„ì‹œì•„ë‚˜", "asiana"],
    "ì§„ì—ì–´": ["ì§„ì—ì–´", "ì§„ ì—ì–´", "jinair", "jin air", "ì§„"],
    "í‹°ì›¨ì´": ["í‹°ì›¨ì´", "í‹°ì›¨ì´í•­ê³µ", "twayair", "tway", "tway air"],
    "ì—ì–´ì„œìš¸": ["ì—ì–´ì„œìš¸", "airseoul", "air seoul"],
    "ì´ìŠ¤íƒ€í•­ê³µ": ["ì´ìŠ¤íƒ€", "ì´ìŠ¤íƒ€í•­ê³µ", "eastar", "eastar jet"],
}

# RAG ë¼ìš°íŒ… í‚¤ì›Œë“œ (ëŒ€í­ í™•ì¥)
RAG_KEYWORDS = [
    # === í™˜ë¶ˆ/ì·¨ì†Œ ê´€ë ¨ ===
    "í™˜ë¶ˆ", "ë¶ˆí™˜", "ë°˜í™˜", "ëŒë ¤", "ëŒë ¤ë°›", "ë¦¬í€", "refund",
    "ì·¨ì†Œ", "ìº”ìŠ¬", "cancel", "cancellation", "í•´ì§€", "ì² íšŒ",
    "ë¶€ë¶„í™˜ë¶ˆ", "ì „ì•¡í™˜ë¶ˆ", "ì¼ë¶€í™˜ë¶ˆ",

    # === ë³€ê²½ ê´€ë ¨ ===
    "ë³€ê²½", "ìˆ˜ì •", "êµí™˜", "ë°”ê¾¸", "ë°”ê¿”", "change", "modify", "modification",
    "ì¼ì •ë³€ê²½", "ë‚ ì§œë³€ê²½", "ì‹œê°„ë³€ê²½", "í¸ëª…ë³€ê²½", "ê²½ë¡œë³€ê²½",
    "ì¬ë°œê¶Œ", "ë¦¬ì´ìŠˆ", "reissue",

    # === ìˆ˜ìˆ˜ë£Œ ê´€ë ¨ ===
    "ìˆ˜ìˆ˜ë£Œ", "fee", "charge", "ë¹„ìš©", "ìš”ê¸ˆ", "ê°€ê²©", "ê¸ˆì•¡",
    "ìœ„ì•½ê¸ˆ", "íŒ¨ë„í‹°", "penalty", "ë²Œê¸ˆ",
    "ë³€ê²½ìˆ˜ìˆ˜ë£Œ", "í™˜ë¶ˆìˆ˜ìˆ˜ë£Œ", "ì·¨ì†Œìˆ˜ìˆ˜ë£Œ", "ì¬ë°œê¶Œìˆ˜ìˆ˜ë£Œ",
    "ë¬´ë£Œ", "ê³µì§œ", "ê½ì§œ", "ê½ì", "ê½ì", "free", "ë©´ì œ",

    # === í•­ê³µê¶Œ/í‹°ì¼“ ê´€ë ¨ ===
    "í•­ê³µê¶Œ", "í‹°ì¼“", "ticket", "í‘œ", "ë¹„í–‰ê¸°í‘œ", "í•­ê³µ", "í•­ê³µí¸",
    "í¸ëª…", "ì¢Œì„", "seat", "booking", "ì˜ˆì•½",

    # === ìš´ì„ ë“±ê¸‰ ===
    "ìš´ì„", "fare", "ë“±ê¸‰", "í´ë˜ìŠ¤", "class",

    # ê¸°ë³¸ ìš´ì„ ë“±ê¸‰ (ì œì£¼í•­ê³µ, ëŒ€í•œí•­ê³µ ë“±)
    "flex", "flexible", "í”Œë ‰ìŠ¤", "í”Œë ‰ì‹œë¸”",
    "standard", "ìŠ¤íƒ ë‹¤ë“œ",
    "saver", "ì„¸ì´ë²„", "save",
    "basic", "ë² ì´ì§", "ë² ì´ì‹",

    # ì´ìŠ¤íƒ€í•­ê³µ/ì•„ì‹œì•„ë‚˜ ìš´ì„ ì¢…ë¥˜
    "íŠ¹ê°€", "íŠ¹ê°€ìš´ì„", "í”„ë¡œëª¨ì…˜", "promotion", "special",
    "í• ì¸", "í• ì¸ìš´ì„", "discount", "ì„¸ì¼",
    "ì¼ë°˜", "ì¼ë°˜ìš´ì„", "ì •ìƒ", "ì •ìƒìš´ì„", "regular", "normal",

    # ì¢Œì„ ë“±ê¸‰
    "premium", "í”„ë¦¬ë¯¸ì—„", "ë¹„ì¦ˆ", "biz", "business",
    "ì´ì½”ë…¸ë¯¸", "economy", "ì¼ë°˜ì„", "ë¹„ì¦ˆë‹ˆìŠ¤ì„", "ì¼ë“±ì„", "í¼ìŠ¤íŠ¸",

    # === ë…¸ì„  êµ¬ë¶„ ===
    "êµ­ë‚´ì„ ", "êµ­ë‚´", "domestic", "ë„ë©”ìŠ¤í‹±",
    "êµ­ì œì„ ", "êµ­ì œ", "international", "ì¸í„°ë‚´ì…”ë„", "í•´ì™¸", "ì™¸êµ­"
    "ë‹¨ê±°ë¦¬", "ì¤‘ê±°ë¦¬", "ì¥ê±°ë¦¬", "short", "medium", "long",

    # === ë…¸ì‡¼ ê´€ë ¨ ===
    "ë…¸ì‡¼", "no-show", "noshow", "ë¯¸íƒ‘ìŠ¹", "ë¯¸ìŠ¹ì„ ", "ë¶ˆíƒ‘ìŠ¹",
    "ë¯¸ì·¨ì†Œ", "ë¯¸ì¶œí˜„", "ë¶ˆì¶œì„", "ì˜ˆì•½ë¶€ë„",
    "ê²Œì´íŠ¸", "gate", "ì¶œêµ¬ì¥", "íƒ‘ìŠ¹êµ¬",
    "íƒ‘ìŠ¹ìˆ˜ì†", "ì²´í¬ì¸", "check-in", "ìˆ˜ì†",

    # === ê¸°ê°„/ì‹œê°„ ê´€ë ¨ ===
    "ê¸°ê°„", "ê¸°í•œ", "ìœ íš¨", "ìœ íš¨ê¸°ê°„", "validity", "ë§Œë£Œ",
    "ì¶œë°œ", "ì¶œë°œì¼", "ì¶œë°œì „", "ì¶œë°œí›„", "departure",
    "ë‹¹ì¼", "ì˜¤ëŠ˜", "ë©°ì¹ ", "ëª‡ì¼", "ë©°ì¹ ì „", "ì¼ì „", "ì „",
    "ì´ì „", "ì´í›„", "before", "after",
    "91ì¼", "90ì¼", "60ì¼", "15ì¼", "14ì¼", "4ì¼", "3ì¼",

    # === ê·œì •/ì •ì±… ê´€ë ¨ ===
    "ê·œì •", "ì •ì±…", "policy", "ì•½ê´€", "ì¡°ê±´", "ê·œì¹™", "rule",
    "ê°€ëŠ¥", "ë¶ˆê°€", "ê°€ëŠ¥í•œ", "ì•ˆë˜", "ë˜ë‚˜", "í• ìˆ˜ìˆ", "í• ìˆ˜ì—†",

    # === í•­ê³µì‚¬ëª… ===
    "ëŒ€í•œí•­ê³µ", "ì•„ì‹œì•„ë‚˜", "ì œì£¼í•­ê³µ", "ì§„ì—ì–´", "í‹°ì›¨ì´",
    "korean", "koreanair", "asiana", "jeju", "jejuair", "jin", "jinair", "tway",

    # === ì§ˆë¬¸ í‚¤ì›Œë“œ ===
    "ì–¸ì œ", "when", "ì–¼ë§ˆ", "how much", "ì–´ë””", "where",
    "ë¬´ì—‡", "what", "ì™œ", "why",
    "ê°€ëŠ¥í•´", "ë˜ë‚˜ìš”", "ì¸ê°€ìš”", "í•œê°€ìš”", "ë‚˜ìš”",
]

# ==========================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================

def expand_query_with_synonyms(query: str) -> str:
    """
    ê²€ìƒ‰ ì¿¼ë¦¬ì— ë™ì˜ì–´ë¥¼ ì¶”ê°€í•˜ì—¬ í™•ì¥
    ì˜ˆ: "ë…¸ì‡¼ ìˆ˜ìˆ˜ë£Œ" â†’ "ë…¸ì‡¼ No-Show ë¯¸íƒ‘ìŠ¹ ìˆ˜ìˆ˜ë£Œ fee ìœ„ì•½ê¸ˆ"
    """
    expanded_terms = []
    words = query.split()

    for word in words:
        word_lower = word.lower()
        # ì›ë³¸ ë‹¨ì–´ ì¶”ê°€
        expanded_terms.append(word)

        # ë™ì˜ì–´ ì‚¬ì „ì—ì„œ ì°¾ê¸°
        if word_lower in SYNONYM_DICT:
            synonyms = SYNONYM_DICT[word_lower]
            for syn in synonyms:
                if syn.lower() != word_lower:
                    expanded_terms.append(syn)

    # ì¤‘ë³µ ì œê±° í›„ ë°˜í™˜
    return " ".join(dict.fromkeys(expanded_terms))


def extract_airline_name(filepath: str) -> str:
    """íŒŒì¼ëª…ì—ì„œ í•­ê³µì‚¬ëª…ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œ"""
    filename = Path(filepath).stem.lower()

    for key, value in AIRLINE_MAPPING.items():
        if key.lower() in filename:
            return value

    # ë§¤í•‘ì— ì—†ìœ¼ë©´ íŒŒì¼ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©
    return Path(filepath).stem


def extract_airline_from_query(q: str) -> list:
    """ì§ˆë¬¸ì—ì„œ í•­ê³µì‚¬ëª… ì¶”ì¶œ"""
    airlines = []
    q_lower = q.lower()

    for airline, keywords in AIRLINE_KEYWORDS.items():
        if any(kw in q_lower for kw in keywords):
            airlines.append(airline)

    return airlines


def route_to_rag(q: str) -> bool:
    """ì§ˆë¬¸ì´ RAGê°€ í•„ìš”í•œì§€ íŒë‹¨"""
    q_lower = q.lower()
    return any(kw.lower() in q_lower for kw in RAG_KEYWORDS)


def get_history_text(n_turns=6):
    """ìµœê·¼ n_turns ê°œì˜ ëŒ€í™”ë§Œ ë°˜í™˜"""
    hist = st.session_state["history"][-n_turns:]
    lines = []
    for role, content in hist:
        prefix = "ì‚¬ìš©ì" if role == "user" else "ì–´ì‹œìŠ¤í„´íŠ¸"
        lines.append(f"{prefix}: {content}")
    return "\n".join(lines) if lines else "ëŒ€í™”ì´ë ¥ ì—†ìŒ"


# ==========================================
# ì‚¬ì´ë“œë°” ì„¤ì •
# ==========================================
with st.sidebar:
    st.header("ğŸ“š ì‚¬ì´ë“œë°” ì˜µì…˜")
    k = st.slider("ê²€ìƒ‰ ê°œìˆ˜ k", 1, 10, 5, help="RAG ê²€ìƒ‰ì‹œ ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜")
    similarity_threshold = st.slider(
        "ìœ ì‚¬ë„ ì„ê³„ê°’",
        0.0, 1.0, 0.3, 0.05,
        help="ì´ ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ë¬¸ì„œë§Œ ì‚¬ìš©"
    )

    show_sources = st.checkbox("ê·¼ê±°(ì†ŒìŠ¤)í‘œì‹œ", value=True)
    show_debug = st.checkbox("ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ", value=False)

    st.divider()

    # ==========================================
    # í•„í„° ê²€ìƒ‰ UI (ì‹ ê·œ ì¶”ê°€)
    # ==========================================
    st.header("ğŸ” í•„í„° ê²€ìƒ‰")
    st.markdown("ì›í•˜ëŠ” ì¡°ê±´ì„ ì„ íƒí•˜ê³  ê²€ìƒ‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”")

    filter_airline = st.selectbox(
        "í•­ê³µì‚¬",
        ["ì„ íƒì•ˆí•¨", "ëŒ€í•œí•­ê³µ", "ì œì£¼í•­ê³µ", "ì§„ì—ì–´", "ì•„ì‹œì•„ë‚˜", "í‹°ì›¨ì´", "ì—ì–´ì„œìš¸"],
        help="í•­ê³µì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )

    filter_route = st.selectbox(
        "ë…¸ì„ ",
        ["ì„ íƒì•ˆí•¨", "êµ­ì œì„ ", "êµ­ë‚´ì„ "],
        help="êµ­ì œì„  ë˜ëŠ” êµ­ë‚´ì„ ì„ ì„ íƒí•˜ì„¸ìš”"
    )

    filter_seat = st.selectbox(
        "ì¢Œì„ ë“±ê¸‰",
        ["ì„ íƒì•ˆí•¨", "ì¼ë°˜ì„", "ë¹„ì¦ˆë‹ˆìŠ¤ì„", "í”„ë¦¬ë¯¸ì—„ì´ì½”ë…¸ë¯¸"],
        help="ì¢Œì„ ë“±ê¸‰ì„ ì„ íƒí•˜ì„¸ìš”"
    )

    filter_regulation = st.selectbox(
        "ê·œì • ì¢…ë¥˜",
        ["ì„ íƒì•ˆí•¨", "í™˜ë¶ˆ", "ë³€ê²½", "ë…¸ì‡¼", "ì·¨ì†Œ"],
        help="ì•Œê³  ì‹¶ì€ ê·œì •ì„ ì„ íƒí•˜ì„¸ìš”"
    )

    # í•„í„° ê²€ìƒ‰ ë²„íŠ¼
    if st.button("ğŸ” í•„í„°ë¡œ ê²€ìƒ‰", type="primary", use_container_width=True, key="filter_search_btn"):
        # í•„í„° ê°’ ìˆ˜ì§‘
        filter_parts = []
        if filter_airline != "ì„ íƒì•ˆí•¨":
            filter_parts.append(filter_airline)
        if filter_route != "ì„ íƒì•ˆí•¨":
            filter_parts.append(filter_route)
        if filter_seat != "ì„ íƒì•ˆí•¨":
            filter_parts.append(filter_seat)
        if filter_regulation != "ì„ íƒì•ˆí•¨":
            filter_parts.append(filter_regulation)

        if filter_parts:
            # í•„í„°ë¥¼ ìì—°ì–´ ì¿¼ë¦¬ë¡œ ë³€í™˜
            filter_query = " ".join(filter_parts)
            # ì„¸ì…˜ì— ì €ì¥í•˜ì—¬ ë©”ì¸ ë¡œì§ì—ì„œ ì²˜ë¦¬
            st.session_state["filter_query"] = filter_query
            st.session_state["filter_display"] = " > ".join(filter_parts)
            st.rerun()
        else:
            st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ í•„í„°ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”")

    st.divider()

    st.header("â“ ì˜ˆì‹œ ì§ˆë¬¸")
    example_questions = [
        "ì œì£¼í•­ê³µ êµ­ì œì„  ë³€ê²½ ìˆ˜ìˆ˜ë£ŒëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
        "ëŒ€í•œí•­ê³µ êµ­ì œì„  í™˜ë¶ˆ ìˆ˜ìˆ˜ë£ŒëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
        "ì§„ì—ì–´ êµ­ì œì„  ë…¸ì‡¼ ìœ„ì•½ê¸ˆì€?",
        "ì•„ì‹œì•„ë‚˜ êµ­ì œì„  íƒ‘ìŠ¹ìˆ˜ì† í›„ ë¯¸íƒ‘ìŠ¹ ìœ„ì•½ê¸ˆ",
        "ëŒ€í•œí•­ê³µ ì¼ë°˜ì„ í™˜ë¶ˆ ìˆ˜ìˆ˜ë£Œ",
    ]
    for q_example in example_questions:
        if st.button(q_example, key=q_example, use_container_width=True):
            st.session_state["example_query"] = q_example

    st.divider()
    c1, c2 = st.columns(2)
    if c1.button("ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘", use_container_width=True):
        st.session_state.pop("messages", None)
        st.session_state.pop("history", None)
        st.session_state.pop("filter_query", None)
        st.session_state.pop("filter_display", None)
        st.cache_resource.clear()
        st.rerun()
    if c2.button("ë©”ëª¨ë¦¬ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.pop("history", None)
        st.success("ë©”ëª¨ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ==========================================
# ì„¸ì…˜ ì´ˆê¸°í™”
# ==========================================
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "history" not in st.session_state:
    st.session_state["history"] = []
if "example_query" not in st.session_state:
    st.session_state["example_query"] = None

# ==========================================
# OpenAI API í‚¤ í™•ì¸
# ==========================================
if "OPENAI_API_KEY" not in os.environ:
    st.warning("âš ï¸ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
    api_key = st.text_input("OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
        st.success("API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()
    else:
        st.stop()

# ==========================================
# LLM ë° í”„ë¡¬í”„íŠ¸ êµ¬ì„±
# ==========================================
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# RAG í”„ë¡¬í”„íŠ¸ (ê°œì„  - í‘œ í˜•ì‹ ì¶œë ¥ ê°•í™”)
rag_prompt = ChatPromptTemplate.from_template(
    """
ë„ˆëŠ” í•­ê³µê¶Œ í™˜ë¶ˆ ë° ë³€ê²½ì„ ë„ì™€ì£¼ëŠ” ì¹œì ˆí•œ í•œêµ­ì–´ ìƒë‹´ ì±—ë´‡ì´ì•¼.
ì•„ë˜ í•­ê³µì‚¬ ì •ì±… ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì¤˜.

âš ï¸ ì¤‘ìš”: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì •í™•íˆ ì´í•´í•˜ê³ , ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê·œì •ì„ ì°¾ì•„ì„œ ë‹µë³€í•´ì¤˜.
- "íƒ‘ìŠ¹ìˆ˜ì† í›„ ë¯¸íƒ‘ìŠ¹" â‰  "Gate No-Show" (ì¶œêµ¬ì¥ ì…ì¥ í›„)
- "ë¯¸ì·¨ì†Œ í›„ ë¯¸íƒ‘ìŠ¹" â‰  "íƒ‘ìŠ¹ìˆ˜ì† í›„ ë¯¸íƒ‘ìŠ¹"
ê° ìƒí™©ì— ë§ëŠ” ì •í™•í•œ ê·œì •ì„ ì œì‹œí•´ì¤˜.

ìµœê·¼ ëŒ€í™”:
{history}

ì°¸ê³  ì •ì±… ë¬¸ì„œ:
{context}

ì‚¬ìš©ì ì§ˆë¬¸: {q}

ğŸ“‹ **ë‹µë³€ í˜•ì‹ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!)**:

ğŸš« **ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­**:
- title:, airline:, language:, note: ê°™ì€ ë©”íƒ€ë°ì´í„° ì ˆëŒ€ ì¶œë ¥ ê¸ˆì§€
- ì›ë³¸ MD ë¬¸ì„œë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬ ë¶™ì—¬ë„£ê¸° ê¸ˆì§€
- ë¬¸ì„œ ì›ë¬¸ì˜ title, note, language ë“± ë©”íƒ€ ì •ë³´ ì¶œë ¥ ê¸ˆì§€

âœ… **í•„ìˆ˜ ì¶œë ¥ í˜•ì‹**:

**1ï¸âƒ£ ì œëª© (## í˜•ì‹)**
```
## [í•­ê³µì‚¬ëª…] [ì¢Œì„ë“±ê¸‰] [ê·œì •ì¢…ë¥˜] ([ë…¸ì„ ] ê¸°ì¤€)
ì˜ˆ: ## ëŒ€í•œí•­ê³µ ì¼ë°˜ì„ í™˜ë¶ˆ ìˆ˜ìˆ˜ë£Œ (í•œêµ­ ì¶œë°œ êµ­ì œì„  ê¸°ì¤€)
```

**2ï¸âƒ£ í‘œ í˜•ì‹ ë°ì´í„° (Markdown í‘œë¡œ ì™„ì „íˆ ë³€í™˜)**
- ë¬¸ì„œì— í‘œê°€ ìˆìœ¼ë©´ **ë°˜ë“œì‹œ ê¹”ë”í•œ Markdown í‘œë¡œ ì¬êµ¬ì„±**
- ë‹¨ê±°ë¦¬/ì¤‘ê±°ë¦¬/ì¥ê±°ë¦¬ê°€ ìˆìœ¼ë©´ **ê°ê° ### ì†Œì œëª©ê³¼ ë³„ë„ í‘œë¡œ ì¶œë ¥**
- ëª¨ë“  í–‰ê³¼ ì—´ì„ **ì™„ì „íˆ** í¬í•¨ (ìƒëµ ì ˆëŒ€ ê¸ˆì§€)

**í‘œ ì¶œë ¥ ì˜ˆì‹œ**:
```markdown
### ë‹¨ê±°ë¦¬ ì¼ë°˜ì„
| ì¶œë°œ ê¸°ì¤€ | FLEX (B,M) | Standard (S,H,E,K,L,U,Q,T) | Saver (L,U,Q,T) |
|---|---:|---:|---:|
| 91ì¼ ì´ìƒ | ë¬´ë£Œ | ë¬´ë£Œ | ë¬´ë£Œ |
| 90~61ì¼ | 30,000ì› | 30,000ì› | 60,000ì› |
| 60~31ì¼ | 50,000ì› | 50,000ì› | 80,000ì› |
| 30~15ì¼ | 60,000ì› | 60,000ì› | 100,000ì› |
| 14~4ì¼ | 70,000ì› | 70,000ì› | ì „ì•¡ í™˜ë¶ˆ ë¶ˆê°€ |
| 3ì¼~ì¶œë°œ | 80,000ì› | 80,000ì› | ì „ì•¡ í™˜ë¶ˆ ë¶ˆê°€ |

### ì¤‘ê±°ë¦¬ ì¼ë°˜ì„
| ì¶œë°œ ê¸°ì¤€ | FLEX | Standard | Saver |
|---|---:|---:|---:|
| 91ì¼ ì´ìƒ | ë¬´ë£Œ | ë¬´ë£Œ | ë¬´ë£Œ |
| 90~61ì¼ | 40,000ì› | 40,000ì› | 80,000ì› |
...

### ì¥ê±°ë¦¬ ì¼ë°˜ì„
| ì¶œë°œ ê¸°ì¤€ | FLEX (B,M,W) | Standard | Saver |
|---|---:|---:|---:|
| 91ì¼ ì´ìƒ | ë¬´ë£Œ | ë¬´ë£Œ | - |
...
```

**3ï¸âƒ£ ì£¼ìš” ì‚¬í•­ ì •ë¦¬ (í•µì‹¬ í¬ì¸íŠ¸ 3-5ê°œ)**
```markdown
**ì£¼ìš” ì‚¬í•­**:
- 91ì¼ ì´ìƒ ì „ ì·¨ì†Œ ì‹œ FLEX/StandardëŠ” ë¬´ë£Œ í™˜ë¶ˆ
- Saver ìš´ì„ì€ ì¶œë°œ 14ì¼ ì „ë¶€í„° ì „ì•¡ í™˜ë¶ˆ ë¶ˆê°€
- ì¥ê±°ë¦¬ ë…¸ì„ ì€ Saver ìš´ì„ì´ ì—†ìŒ
- ì¶œë°œì¼ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í™˜ë¶ˆ ìˆ˜ìˆ˜ë£Œê°€ ì¦ê°€
```

**4ï¸âƒ£ ì•ˆë‚´ ë¬¸êµ¬ (í•„ìˆ˜)**
```markdown
âš ï¸ ì •í™•í•œ ì •ë³´ëŠ” í•´ë‹¹ í•­ê³µì‚¬ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.
```

âš ï¸ **ì²´í¬ë¦¬ìŠ¤íŠ¸ (ëª¨ë‘ ë§Œì¡±í•´ì•¼ í•¨)**:
- [ ] ë©”íƒ€ë°ì´í„°(title, note, language, airline) ì™„ì „íˆ ì œê±°ë¨?
- [ ] í‘œê°€ ì™„ì „í•œ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜ë¨?
- [ ] ë‹¨ê±°ë¦¬/ì¤‘ê±°ë¦¬/ì¥ê±°ë¦¬ ê°ê° ë³„ë„ í‘œë¡œ ì¶œë ¥ë¨?
- [ ] ëª¨ë“  ìš´ì„ ë“±ê¸‰(FLEX, Standard, Saver ë“±) í¬í•¨ë¨?
- [ ] ëª¨ë“  ê¸°ê°„(91ì¼ ì´ìƒ, 90~61ì¼ ë“±) í¬í•¨ë¨?
- [ ] ì£¼ìš” ì‚¬í•­ì´ ì •ë¦¬ë¨?
- [ ] ì•ˆë‚´ ë¬¸êµ¬ê°€ í¬í•¨ë¨?

ë‹µë³€:
"""
)
rag_chain = rag_prompt | llm | StrOutputParser()

# ì¼ë°˜ ëŒ€í™” í”„ë¡¬í”„íŠ¸
base_prompt = ChatPromptTemplate.from_template(
    """
ë„ˆëŠ” í•­ê³µê¶Œ í™˜ë¶ˆ ë° ë³€ê²½ì„ ë„ì™€ì£¼ëŠ” ì¹œì ˆí•œ í•œêµ­ì–´ ìƒë‹´ ì±—ë´‡ì´ì•¼.
í•­ê³µê¶Œ í™˜ë¶ˆ/ì·¨ì†Œì™€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì´ë©´ ì •ì¤‘íˆ ì•ˆë‚´í•˜ê³ , í™˜ë¶ˆ ê´€ë ¨ ì§ˆë¬¸ì„ ìœ ë„í•´ì¤˜.

ìµœê·¼ ëŒ€í™”:
{history}

ì‚¬ìš©ì: {q}

ë‹µë³€:
"""
)
base_chain = base_prompt | llm | StrOutputParser()

# ==========================================
# ë²¡í„° DB ì´ˆê¸°í™”
# ==========================================
@st.cache_resource
def initialize_vectordb():
    """MD íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ê³  ë²¡í„° DBë¥¼ ìƒì„±"""

    # íŒŒì¼ íŒ¨í„´
    patterns = [
        # "/content/data/airlines_md/*.md",
        # "./data/airlines_md/*.md",
        "data/airlines_md/*.md",
    ]

    seen = set()
    loader_files = []

    for pat in patterns:
        for fp in glob.glob(pat, recursive=True):
            if fp.endswith(".md") and fp not in seen and Path(fp).is_file():
                seen.add(fp)
                loader_files.append(fp)

    # ë¡œë“œ ê²°ê³¼ í‘œì‹œ
    st.caption(f"ğŸ“„ ë¡œë“œëœ MD íŒŒì¼ ìˆ˜: {len(loader_files)}")
    if loader_files:
        with st.expander("ğŸ“‚ ë¡œë“œëœ íŒŒì¼ ëª©ë¡", expanded=True):
            for fp in loader_files:
                airline = extract_airline_name(fp)
                st.text(f"{airline}: {fp}")

    if not loader_files:
        st.error("âŒ MD íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.info("""
        ğŸ’¡ **í•´ê²° ë°©ë²•:**
        - ì½”ë©: `/content/data/airlines_md/` í´ë”ì— MD íŒŒì¼ ì—…ë¡œë“œ
        - ë¡œì»¬: `./data/airlines_md/` í´ë”ì— MD íŒŒì¼ ì €ì¥
        """)
        st.stop()

    # ë¬¸ì„œ ë¡œë”©
    all_docs = []
    airline_set = set()

    for fp in loader_files:
        try:
            docs = TextLoader(fp, encoding="utf-8").load()
        except Exception as e:
            st.warning(f"âš ï¸ ë¡œë“œ ì‹¤íŒ¨: {fp} ({e})")
            continue

        airline_tag = extract_airline_name(fp)
        airline_set.add(airline_tag)

        for d in docs:
            if not d.page_content or not d.page_content.strip():
                continue
            d.metadata["airline"] = airline_tag
            d.metadata["source_path"] = fp
            d.metadata["filename"] = Path(fp).name
            all_docs.append(d)

    if not all_docs:
        st.error("âŒ ë¬¸ì„œë¥¼ ë¡œë“œí–ˆì§€ë§Œ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        st.stop()

    # ì²­í¬ ë¶„í•  (í‘œ ë³´ì¡´ì„ ìœ„í•´ í¬ê¸° ì¦ê°€)
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=2000,  # í‘œë¥¼ í¬í•¨í•˜ë„ë¡ í¬ê¸° ì¦ê°€
        chunk_overlap=400,  # ì˜¤ë²„ë© ì¦ê°€
        separators=[
            "\n\n## ",
            "\n\n### ",
            "\n\n",
            "\n",
            ". ",
            " ",
            ""
        ]
    )
    chunks = splitter.split_documents(all_docs)

    if not chunks:
        st.error("âŒ ì²­í¬ ë¶„í•  ê²°ê³¼ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
        st.stop()

    # ì„ë² ë”© ë° ë²¡í„° DB ìƒì„±
    emb = OpenAIEmbeddings(model="text-embedding-3-small")
    db = Chroma.from_documents(chunks, emb)

    st.success(f"âœ… ì¸ë±ì‹± ì™„ë£Œ: ë¬¸ì„œ {len(all_docs)}ê±´, ì²­í¬ {len(chunks)}ê±´")

    # í•­ê³µì‚¬ ëª©ë¡ ì €ì¥
    st.session_state["available_airlines"] = sorted(list(airline_set))

    return db

# ë²¡í„° DB ì´ˆê¸°í™”
db = initialize_vectordb()

# í•­ê³µì‚¬ ì •ë³´ í‘œì‹œ
if "available_airlines" in st.session_state:
    with st.sidebar:
        st.info(f"ğŸ¢ ì‚¬ìš© ê°€ëŠ¥í•œ í•­ê³µì‚¬: {', '.join(st.session_state['available_airlines'])}")

# ==========================================
# RAG ë‹µë³€ ìƒì„± (ìµœì í™” ë²„ì „)
# ==========================================
def refund_rag(q, k_override=None, threshold=None):
    """
    RAGë¥¼ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„± (ìµœì í™”)
    - í•œì˜ ë™ì˜ì–´ í™•ì¥ ì§€ì›
    - í•­ê³µì‚¬ í•„í„°ë§ ê°•í™”
    - í‘œ ë°ì´í„° ìµœì í™”
    - ëª…í™•í•œ ì—ëŸ¬ ì²˜ë¦¬
    """
    kk = k_override if k_override is not None else k
    th = threshold if threshold is not None else similarity_threshold

    try:
        # 1ï¸âƒ£ ì§ˆë¬¸ ë¶„ì„
        query_airlines = extract_airline_from_query(q)
        expanded_query = expand_query_with_synonyms(q)

        # 2ï¸âƒ£ ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„± (í•­ê³µì‚¬ëª… ê°€ì¤‘ì¹˜ ì¦ê°€)
        if query_airlines:
            # í•­ê³µì‚¬ëª…ì„ 2ë²ˆ ë°˜ë³µí•˜ì—¬ ê°€ì¤‘ì¹˜ ì¦ê°€
            search_query = f"{' '.join(query_airlines)} {' '.join(query_airlines)} {expanded_query}"
        else:
            search_query = expanded_query

        # 3ï¸âƒ£ ê²€ìƒ‰ ê°œìˆ˜ ë™ì  ì¡°ì •
        is_table_query = any(kw in q for kw in ["ìˆ˜ìˆ˜ë£Œ", "ìœ„ì•½ê¸ˆ", "ìš”ê¸ˆ", "ë¹„ìš©", "í™˜ë¶ˆ", "ë³€ê²½", "ì·¨ì†Œ"])
        search_k = kk * 3 if is_table_query else kk * 2

        # 4ï¸âƒ£ ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
        if show_debug:
            st.info(f"ğŸ” ì›ë³¸ ì¿¼ë¦¬: `{q}`")
            st.info(f"ğŸ” í™•ì¥ëœ ì¿¼ë¦¬: `{expanded_query}`")
            st.info(f"ğŸ¢ ê°ì§€ëœ í•­ê³µì‚¬: {', '.join(query_airlines) if query_airlines else 'ì—†ìŒ'}")
            st.info(f"ğŸ“Š ê²€ìƒ‰ ê°œìˆ˜: {search_k} (í‘œ ë°ì´í„°: {'ì˜ˆ' if is_table_query else 'ì•„ë‹ˆì˜¤'})")

        # 5ï¸âƒ£ ë²¡í„° DB ê²€ìƒ‰
        all_results = db.similarity_search_with_relevance_scores(search_query, k=search_k)

        # 6ï¸âƒ£ í•­ê³µì‚¬ í•„í„°ë§ (ëª…ì‹œëœ ê²½ìš° ê°•ì œ ì ìš©)
        if query_airlines:
            filtered_results = []
            for d, score in all_results:
                doc_airline = d.metadata.get('airline', '')
                if any(qa in doc_airline for qa in query_airlines):
                    # í•­ê³µì‚¬ ì§€ì • ì‹œ ì„ê³„ê°’ ì™„í™” (20% ë‚®ì¶¤)
                    relaxed_threshold = th * 0.8
                    if score >= relaxed_threshold:
                        filtered_results.append((d, score))

            # í•„í„°ë§ ê²°ê³¼ í™•ì¸
            if not filtered_results:
                missing_airlines = ', '.join(query_airlines)
                error_msg = f"""
âŒ **{missing_airlines}** í•­ê³µì‚¬ì˜ ê´€ë ¨ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

**í™•ì¸ ì‚¬í•­:**
1. ë¡œë“œëœ í•­ê³µì‚¬ ëª©ë¡ì„ í™•ì¸í•´ì£¼ì„¸ìš” (ì‚¬ì´ë“œë°” ì°¸ì¡°)
2. í•­ê³µì‚¬ëª… í‘œê¸°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”:
   - "ì§„ì—ì–´" / "JIN AIR"
   - "ì•„ì‹œì•„ë‚˜" / "ASIANA"
   - "ëŒ€í•œí•­ê³µ" / "KOREAN AIR"

**í•´ê²° ë°©ë²•:**
- ìœ ì‚¬ë„ ì„ê³„ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš” (í˜„ì¬: {th:.2f} â†’ ê¶Œì¥: 0.2~0.3)
- í•­ê³µì‚¬ëª…ì„ ìƒëµí•˜ê³  ê²€ìƒ‰í•´ë³´ì„¸ìš” (ì˜ˆ: "êµ­ì œì„  ë…¸ì‡¼ ìœ„ì•½ê¸ˆ")
- ë””ë²„ê·¸ ëª¨ë“œë¥¼ ì¼œì„œ ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”
"""
                if show_debug:
                    st.warning("ğŸ” ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ (í•„í„°ë§ ì „):")
                    for i, (d, score) in enumerate(all_results[:10], 1):
                        airline = d.metadata.get('airline', 'ì•Œ ìˆ˜ ì—†ìŒ')
                        st.write(f"[{i}] **{airline}** - ìœ ì‚¬ë„: {score:.3f}")

                return error_msg, []

            results = filtered_results[:kk]
        else:
            # í•­ê³µì‚¬ ë¯¸ì§€ì • ì‹œ ì¼ë°˜ ì„ê³„ê°’ ì ìš©
            results = [(d, score) for d, score in all_results if score >= th]
            results = results[:kk]

        # 7ï¸âƒ£ ìµœì¢… ê²°ê³¼ ê²€ì¦
        if not results:
            fallback_msg = f"""
ê´€ë ¨ ê·œì •ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ğŸ˜¥

**ì‹œë„í•œ ê²€ìƒ‰ì–´:** `{expanded_query}`

**ê°€ëŠ¥í•œ ì›ì¸:**
- ìœ ì‚¬ë„ ì„ê³„ê°’({th:.2f})ì´ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤
- ì§ˆë¬¸ì´ ë„ˆë¬´ ì¶”ìƒì ì´ê±°ë‚˜ ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤

**í•´ê²° ë°©ë²•:**
1. ìœ ì‚¬ë„ ì„ê³„ê°’ì„ **0.2~0.3**ìœ¼ë¡œ ë‚®ì¶°ë³´ì„¸ìš”
2. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ë³´ì„¸ìš”
   - ì¢‹ì€ ì˜ˆ: "ì œì£¼í•­ê³µ êµ­ì œì„  BASIC ìš´ì„ ì¶œë°œ 3ì¼ ì „ ë³€ê²½ ìˆ˜ìˆ˜ë£Œ"
3. í•­ê³µì‚¬ëª…ì„ ëª…í™•íˆ í•´ì£¼ì„¸ìš”
"""
            return fallback_msg, []

        # 8ï¸âƒ£ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ì¤‘ë³µ ì œê±°)
        context_parts = []
        seen_content = set()

        for d, score in results:
            content = d.page_content
            if content in seen_content:
                continue
            seen_content.add(content)

            airline = d.metadata.get('airline', 'ì•Œ ìˆ˜ ì—†ìŒ')
            context_parts.append(f"[{airline} ê·œì • | ìœ ì‚¬ë„: {score:.2f}]\n{content}")

        context = "\n\n" + "="*50 + "\n\n".join(context_parts)
        history_text = get_history_text()

        # 9ï¸âƒ£ LLM í˜¸ì¶œ
        answer = rag_chain.invoke({
            "history": history_text,
            "context": context,
            "q": q
        })

        # ğŸ”Ÿ ì†ŒìŠ¤ ì •ë³´ ìƒì„±
        sources = []
        for d, score in results:
            airline = d.metadata.get('airline', 'ì•Œ ìˆ˜ ì—†ìŒ')
            filename = d.metadata.get('filename', 'ì•Œ ìˆ˜ ì—†ìŒ')
            preview = d.page_content[:300].replace('\n', ' ')
            sources.append({
                "airline": airline,
                "filename": filename,
                "score": score,
                "content": preview,
                "full_content": d.page_content
            })

        return answer, sources

    except Exception as e:
        error_msg = f"âŒ RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        st.error(error_msg)
        import traceback
        if show_debug:
            st.error(f"ìƒì„¸ ì˜¤ë¥˜:\n```\n{traceback.format_exc()}\n```")
        return error_msg, []

# ==========================================
# ì±„íŒ… UI
# ==========================================
for m in st.session_state["messages"]:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ==========================================
# í•„í„° ê²€ìƒ‰ ì²˜ë¦¬ (ì‹ ê·œ ì¶”ê°€)
# ==========================================
if st.session_state.get("filter_query"):
    filter_query = st.session_state.pop("filter_query")
    filter_display = st.session_state.pop("filter_display")

    # ì‚¬ìš©ì ë©”ì‹œì§€ë¡œ í•„í„° ì •ë³´ í‘œì‹œ
    user_message = f"**í˜„ì¬ ì ìš©ëœ í•„í„°**: {filter_display}"
    with st.chat_message("user"):
        st.markdown(user_message)
    st.session_state["messages"].append({"role": "user", "content": user_message})
    st.session_state["history"].append(("user", user_message))

    # RAGë¡œ ê²€ìƒ‰í•˜ì—¬ LLM ë‹µë³€ ìƒì„±
    with st.chat_message("assistant"):
        try:
            with st.spinner("ğŸ” í•„í„° ì¡°ê±´ì— ë§ëŠ” ê·œì •ì„ ê²€ìƒ‰ ì¤‘..."):
                ans, sources = refund_rag(filter_query, k_override=k)

            st.markdown(ans)
            st.success("âœ… í•­ê³µê¶Œ í™˜ë¶ˆ ê·œì •ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # ë””ë²„ê·¸ ì •ë³´
            if show_debug and sources:
                with st.expander("ğŸ› ë””ë²„ê·¸ ì •ë³´", expanded=False):
                    st.write(f"í•„í„° ì¿¼ë¦¬: {filter_query}")
                    st.write(f"ê²€ìƒ‰ëœ ì²­í¬ ìˆ˜: {len(sources)}")
                    st.write(f"ìœ ì‚¬ë„ ì„ê³„ê°’: {similarity_threshold}")
                    for i, src in enumerate(sources, 1):
                        st.write(f"**[{i}] {src['airline']}** ({src['filename']}) - ìœ ì‚¬ë„: {src['score']:.3f}")

            # ì°¸ê³  ê·¼ê±°
            if show_sources and sources:
                with st.expander("ğŸ” ì°¸ê³  ê·¼ê±° ë¬¸ì„œ ë³´ê¸°", expanded=False):
                    for i, src in enumerate(sources, 1):
                        st.markdown(f"### ğŸ“‹ [{i}] {src['airline']} (ìœ ì‚¬ë„: {src['score']:.2f})")
                        st.markdown(f"**íŒŒì¼**: `{src['filename']}`")
                        st.markdown(f"```\n{src['content'][:500]}...\n```")

                        if st.checkbox(f"ì „ì²´ ë‚´ìš© ë³´ê¸° [{i}]", key=f"full_filter_{i}"):
                            st.text_area(
                                "ì „ì²´ ë‚´ìš©",
                                src['full_content'],
                                height=300,
                                key=f"full_filter_text_{i}"
                            )
                        st.markdown("---")

        except Exception as e:
            error_message = f"âŒ í•„í„° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            st.error(error_message)
            ans = error_message

    # ë©”ì‹œì§€ ì €ì¥
    st.session_state["messages"].append({"role": "assistant", "content": ans})
    st.session_state["history"].append(("assistant", ans))

# ==========================================
# ì¼ë°˜ ì±„íŒ… ì…ë ¥ ì²˜ë¦¬
# ==========================================
# ì…ë ¥ ì²˜ë¦¬
user_input = None
if st.session_state.get("example_query"):
    user_input = st.session_state["example_query"]
    st.session_state["example_query"] = None
else:
    user_input = st.chat_input("í•­ê³µê¶Œ í™˜ë¶ˆ/ë³€ê²½ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš” (ì˜ˆ: 'ì§„ì—ì–´ ë…¸ì‡¼ ìœ„ì•½ê¸ˆì€?')")

if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state["messages"].append({"role": "user", "content": user_input})
    st.session_state["history"].append(("user", user_input))

    # íˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œí•œ
    if len(st.session_state["history"]) > 20:
        st.session_state["history"] = st.session_state["history"][-20:]

    # RAG ë¼ìš°íŒ…
    use_rag = route_to_rag(user_input)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ
    with st.chat_message("assistant"):
        try:
            if use_rag:
                # RAG ë‹µë³€
                with st.spinner("ğŸ” ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
                    ans, sources = refund_rag(user_input, k_override=k)

                st.markdown(ans)
                st.success("âœ… í•­ê³µê¶Œ í™˜ë¶ˆ ê·œì •ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ë˜ì—ˆìŠµë‹ˆë‹¤.")

                # ë””ë²„ê·¸ ì •ë³´
                if show_debug and sources:
                    with st.expander("ğŸ› ë””ë²„ê·¸ ì •ë³´", expanded=False):
                        st.write(f"ê²€ìƒ‰ëœ ì²­í¬ ìˆ˜: {len(sources)}")
                        st.write(f"ìœ ì‚¬ë„ ì„ê³„ê°’: {similarity_threshold}")
                        detected_airlines = extract_airline_from_query(user_input)
                        if detected_airlines:
                            st.write(f"ê°ì§€ëœ í•­ê³µì‚¬: {', '.join(detected_airlines)}")
                        for i, src in enumerate(sources, 1):
                            st.write(f"**[{i}] {src['airline']}** ({src['filename']}) - ìœ ì‚¬ë„: {src['score']:.3f}")

                # ì°¸ê³  ê·¼ê±°
                if show_sources and sources:
                    with st.expander("ğŸ” ì°¸ê³  ê·¼ê±° ë¬¸ì„œ ë³´ê¸°", expanded=False):
                        for i, src in enumerate(sources, 1):
                            st.markdown(f"### ğŸ“‹ [{i}] {src['airline']} (ìœ ì‚¬ë„: {src['score']:.2f})")
                            st.markdown(f"**íŒŒì¼**: `{src['filename']}`")
                            st.markdown(f"```\n{src['content']}...\n```")

                            if st.checkbox(f"ì „ì²´ ë‚´ìš© ë³´ê¸° [{i}]", key=f"full_{i}"):
                                st.text_area(
                                    "ì „ì²´ ë‚´ìš©",
                                    src['full_content'],
                                    height=300,
                                    key=f"full_text_{i}"
                                )
                            st.markdown("---")
            else:
                # ì¼ë°˜ ëŒ€í™”
                history_text = get_history_text()
                with st.spinner("ğŸ’¬ ë‹µë³€ ìƒì„± ì¤‘..."):
                    ans = base_chain.invoke({"history": history_text, "q": user_input})

                st.markdown(ans)
                st.info("ğŸ’¬ ì¼ë°˜ ëŒ€í™”ë¡œ ë‹µë³€ë˜ì—ˆìŠµë‹ˆë‹¤. í™˜ë¶ˆ/ì·¨ì†Œ ê´€ë ¨ ì§ˆë¬¸ì€ ìë™ìœ¼ë¡œ ê·œì •ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.")

        except Exception as e:
            error_message = f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            st.error(error_message)
            ans = error_message

    # ë©”ì‹œì§€ ì €ì¥
    st.session_state["messages"].append({"role": "assistant", "content": ans})
    st.session_state["history"].append(("assistant", ans))

# ==========================================
# í•˜ë‹¨ ì•ˆë‚´ ë° í‘¸í„°
# ==========================================
st.markdown("---")
st.caption("âš ï¸ ë³¸ ì±—ë´‡ì€ ì°¸ê³ ìš©ì´ë©°, ì •í™•í•œ ì •ë³´ëŠ” í•­ê³µì‚¬ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ë˜ëŠ” ê³ ê°ì„¼í„°ë¥¼ í†µí•´ í™•ì¸í•´ì£¼ì„¸ìš”.")

with st.expander("â„¹ï¸ ì‚¬ìš© ê°€ì´ë“œ", expanded=False):
    st.markdown("""
    ### ğŸ’¡ ì‚¬ìš© íŒ

    1. **í•­ê³µì‚¬ëª…ì„ ëª…í™•íˆ ëª…ì‹œí•˜ì„¸ìš”**
       - âŒ "ë³€ê²½ ìˆ˜ìˆ˜ë£ŒëŠ”?"
       - âœ… "ì œì£¼í•­ê³µ êµ­ì œì„  ë³€ê²½ ìˆ˜ìˆ˜ë£ŒëŠ”?"

    2. **êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”**
       - âŒ "í™˜ë¶ˆ ë˜ë‚˜ìš”?"
       - âœ… "ì œì£¼í•­ê³µ BASIC ìš´ì„ ì¶œë°œ 5ì¼ ì „ ë³€ê²½ ìˆ˜ìˆ˜ë£ŒëŠ”?"

    3. **ìœ ì‚¬ë„ ì„ê³„ê°’ ì¡°ì •**
       - ë‹µë³€ì´ ì—†ë‹¤ë©´ ì„ê³„ê°’ì„ **0.2~0.3**ìœ¼ë¡œ ë‚®ì¶°ë³´ì„¸ìš”

    4. **ê·¼ê±° ë¬¸ì„œ í™•ì¸**
       - "ê·¼ê±°(ì†ŒìŠ¤)í‘œì‹œ" ì˜µì…˜ìœ¼ë¡œ ì°¸ê³  ê·œì • í™•ì¸ ê°€ëŠ¥

    5. **ë””ë²„ê·¸ ëª¨ë“œ í™œìš©**
       - ê²€ìƒ‰ ê³¼ì •ì„ ìƒì„¸íˆ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œ í™œì„±í™”

    6. **í•œì˜ í˜¼ìš© ê²€ìƒ‰ ì§€ì›**
       - "ë…¸ì‡¼" â†’ "No-Show"ë¡œ ìë™ í™•ì¥
       - "í™˜ë¶ˆ" â†’ "refund"ë¡œ ìë™ í™•ì¥
    """)
